{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../../src/features/feature_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../src/features/feature_utils.py\n",
    "# %load ../../src/feature/feature_utils.py\n",
    "# %%writefile ../../src/features/feature_utils.py\n",
    "\"\"\"\n",
    "Author: Jim Clauwaert\n",
    "Created in the scope of my PhD\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels import robust\n",
    "\n",
    "def AllocatePromoters(experiment, IDs):\n",
    "    \n",
    "    TSS_info = pd.read_csv(\"../data/external/TSS_info.csv\")\n",
    "    TSS_seq = pd.read_csv(\"../data/external/TSS_seq.csv\")\n",
    "    mask = (TSS_seq[\"strand\"] == \"+\") & (TSS_info[\"sigma_binding\"].str.count(experiment[-1]) == 1) & (TSS_seq[\"conditions\"].str.count(\"E\") == 1)\n",
    "    TSS = TSS_seq.loc[mask,\"TSS_position\"].values\n",
    "    positions = [int(id[-8:]) for id in IDs]\n",
    "\n",
    "    mask_promoters = []\n",
    "    for position in positions:\n",
    "        mask_promoters.append(((position+35 <= TSS) & (position+60 > TSS)).any())\n",
    "    \n",
    "    return mask_promoters\n",
    "\n",
    "def BinaryOneHotEncoder(Y_bool):\n",
    "    hot_array = np.zeros([len(Y_bool), 2], dtype=np.int8)\n",
    "    for i in range(len(Y_bool)): \n",
    "        if Y_bool[i] == True:\n",
    "            hot_array[i,1]=1 \n",
    "        else:\n",
    "            hot_array[i,0]=1\n",
    "    \n",
    "    return hot_array\n",
    "\n",
    "\n",
    "def CreateBalancedTrainTest(X,Y, test_size=0.1):\n",
    "    Y_0 = Y[Y[:,1]==0]\n",
    "    Y_1 = Y[Y[:,1]==1]\n",
    "\n",
    "    X_0 = X[Y[:,1]==0]\n",
    "    X_1 = X[Y[:,1]==1]\n",
    "\n",
    "    X_train_0, X_test_0, Y_train_0, Y_test_0= train_test_split(X_0, Y_0, test_size=test_size)\n",
    "    X_train_1, X_test_1, Y_train_1, Y_test_1= train_test_split(X_1, Y_1, test_size=test_size)\n",
    "\n",
    "    X_train = np.vstack((X_train_0, X_train_1))\n",
    "    Y_train = np.vstack((Y_train_0, Y_train_1))\n",
    "    X_test = np.vstack((X_test_0, X_test_1))\n",
    "    Y_test = np.vstack((Y_test_0, Y_test_1))\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n",
    "def CreateImageFromSequences(sequences, length= 50):\n",
    "\n",
    "    lib = np.zeros((len(sequences),length, 4))\n",
    "    index = 0\n",
    "    cut = 0\n",
    "    for string in sequences:\n",
    "        length_seq = len(sequences[index])\n",
    "        diff = length - length_seq\n",
    "        if diff<0:\n",
    "            cut+=1\n",
    "            pre_map = None\n",
    "            string = string[-50:]\n",
    "            length_seq = 50\n",
    "            diff = 0\n",
    "        pre_map = np.full(diff,0.25, dtype=np.float16)  \n",
    "        Amap = np.hstack((pre_map, [(x==y)*1 for (x,y) in zip(string,\"A\"*length_seq)]))\n",
    "        Tmap = np.hstack((pre_map, [(x==y)*1 for (x,y) in zip(string,\"T\"*length_seq)]))\n",
    "        Cmap = np.hstack((pre_map, [(x==y)*1 for (x,y) in zip(string,\"C\"*length_seq)]))\n",
    "        Gmap = np.hstack((pre_map, [(x==y)*1 for (x,y) in zip(string,\"G\"*length_seq)]))\n",
    "        image = np.array([Amap,Tmap,Cmap,Gmap], dtype=np.float16)\n",
    "        \n",
    "\n",
    "        lib[index,:,:] = np.transpose(image)\n",
    "        index+=1\n",
    "    if cut>0:\n",
    "        print(\"{} sequences have been cut\".format(cut))\n",
    "    \n",
    "    return lib\n",
    "\n",
    "def DetectPeaks(scores, cutoff, smoothing=True, window_len=50):\n",
    "    peak_index = []\n",
    "    index_list = []\n",
    "    if smoothing is True:\n",
    "        scores = Smooth(scores, window_len=window_len)\n",
    "    for i,B in enumerate(scores>cutoff):\n",
    "        if B == True:\n",
    "            if (scores[i]<scores[i-1] and scores[i]<scores[i-2]) and scores[i-2]>scores[i-3]:\n",
    "                peak_index.append(i-2)\n",
    "                \n",
    "    mask = np.full(len(scores),False)\n",
    "    mask[peak_index] = True\n",
    "    \n",
    "    return peak_index, mask\n",
    "\n",
    "\n",
    "def Smooth(x,window_len=50,window='hanning'):\n",
    "        s=np.r_[2*x[0]-x[window_len-1::-1],x,2*x[-1]-x[-1:-window_len:-1]]\n",
    "        if window == 'flat': #moving average\n",
    "                w=np.ones(window_len,'d')\n",
    "        else:  \n",
    "                w=eval('np.{}(window_len)'.format(window))\n",
    "        y=np.convolve(w/w.sum(),s,mode='same')\n",
    "        \n",
    "        return y[window_len:-window_len+1]\n",
    "\n",
    "def LoadValidationData():\n",
    "\n",
    "    A_raw = pd.read_csv(\"../data/external/anderson_NN.csv\")\n",
    "    A_X, A_Y = CreateImageFromSequences(A_raw[\"PROBE_SEQUENCE\"]), A_raw[\"PM\"]\n",
    "    B_raw = pd.read_csv(\"../data/external/brewster_NN.csv\")\n",
    "    B_X, B_Y = CreateImageFromSequences(B_raw[\"PROBE_SEQUENCE\"]), B_raw[\"PM\"]\n",
    "    R_raw = pd.read_csv(\"../data/external/rand_mut_NN.csv\")\n",
    "    R_X, R_Y = CreateImageFromSequences(R_raw[\"PROBE_SEQUENCE\"]), R_raw[\"PM\"]\n",
    "    M_raw = pd.read_csv(\"../data/external/mod_mut_NN.csv\")\n",
    "    M_X, M_Y = CreateImageFromSequences(M_raw[\"PROBE_SEQUENCE\"]), M_raw[\"PM\"]\n",
    "    D_raw = pd.read_csv(\"../data/external/davis_NN.csv\")\n",
    "    D_X, D_Y = CreateImageFromSequences(D_raw[\"PROBE_SEQUENCE\"]), D_raw[\"PM\"]\n",
    "\n",
    "    return A_X, A_Y, B_X, B_Y, R_X, R_Y, M_X, M_Y, D_X, D_Y\n",
    "\n",
    "def LoadDataTSS(path, experiment):\n",
    "    data_extra = pd.read_csv(path)\n",
    "    sequences_extra = data_extra[\"PROBE_SEQUENCE\"]\n",
    "    X_extra = CreateImageFromSequences(sequences_extra)\n",
    "    Y_extra_raw = data_extra[experiment]\n",
    "    Y_extra = BinaryOneHotEncoder(Y_extra_raw==1)\n",
    "    \n",
    "    return X_extra, Y_extra\n",
    "\n",
    "\n",
    "\n",
    "def TransformDataSimple(data_ip, data_mock_ip):\n",
    "\n",
    "    list_mock_ip = []\n",
    "    list_ip = []\n",
    "\n",
    "    for datafile in data_ip:\n",
    "        list_ip.append(pd.read_csv(datafile)[\"PM\"].values)\n",
    "    for datafile in data_mock_ip:\n",
    "        list_mock_ip.append(pd.read_csv(datafile)[\"PM\"].values)\n",
    "            \n",
    "    datafile = pd.read_csv(data_ip[0])\n",
    "    sequences = datafile[\"PROBE_SEQUENCE\"].values\n",
    "    IDs = datafile[\"PROBE_ID\"].values\n",
    "    \n",
    "    list_ip = np.vstack(list_ip).T\n",
    "    list_mock_ip = np.vstack(list_mock_ip).T\n",
    "    log_list_ip = np.log2(list_ip)\n",
    "    log_mock_list_ip = np.log2(list_mock_ip)\n",
    "\n",
    "    median_ip = [np.median(log_list_ip[:,u]) for u in range(np.shape(list_ip)[1])]\n",
    "    mad_ip = [robust.mad(log_list_ip[:,u]) for u in range(np.shape(list_ip)[1])]\n",
    "    mock_median_ip = [np.median(log_mock_list_ip[:,u]) for u in range (np.shape(list_ip)[1])]\n",
    "    mock_mad_ip = [robust.mad(log_mock_list_ip[:,u]) for u in range(np.shape(list_ip)[1])]\n",
    "    \n",
    "    ip_norm = np.array([(log_list_ip[:,u]-median_ip[u])/mad_ip[u] for u in range(len(mad_ip))]).T\n",
    "    mock_ip_norm = np.array([(log_mock_list_ip[:,u]-mock_median_ip[u])/mock_mad_ip[u] for u in range(len(mad_ip))]).T\n",
    "    \n",
    "    fold = ip_norm-mock_ip_norm\n",
    "    mean_fold = np.mean(fold,axis=1)\n",
    "    \n",
    "    ip_norm_mean = np.mean(ip_norm, axis=1)\n",
    "    mock_ip_norm_mean = np.mean(mock_ip_norm, axis=1)\n",
    "    fold_mean = ip_norm_mean - mock_ip_norm_mean\n",
    "\n",
    "    sequences_img = CreateImageFromSequences(sequences)\n",
    "\n",
    "    return  sequences_img, mean_fold, sequences, IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
